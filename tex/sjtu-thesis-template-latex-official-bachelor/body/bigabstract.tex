%%==================================================
%% bigabstract.tex for SJTU Bachelor Thesis
%% version: 0.5.2
%% Encoding: UTF-8
%%==================================================

\begin{bigabstract}

In the era of network and information, the exchange of academic research results of various disciplines naturally becomes more frequent and indispensable, among which the most frequently used part of our daily study life is the academic paper that infused the wisdom and research results of other researchers It is usually necessary to purchase a book that you want to read at your own expense or to rely on the corresponding academic institution to collectively buy it, for example, the IEEE database and the domestic Chinese knowledge network. Of course, there are similar sites like arXiv can be downloaded free of charge to download the above papers. However, these database problems There is almost no intersection between the stored data in the paper, which leads to the fact that if a particular paper is to be searched, it is sometimes necessary to traverse several databases to find a specifically desired paper, which significantly increases the unnecessary time spent in academic research. Similar to the situation has also appeared before, that is, in the early development of the Internet, the various sites are not completely interlinked, the lack of a suitable The number of guided tools lead to the relative occlusion of the network, and the emergence of the portal after the search engine is to fill the vacancy, so that the entire network really connected to each other, but also to facilitate the browsing of all users on the Internet. In the field of academic papers in the field, the corresponding tool is the academic search engine.

In today's world, the more widely used, the number of users of the academic search engine should be the number of Google developed Google Google Scholar site.This site is currently open, the largest amount of data, the most convenient academic search engine. This search engine is used in a way similar to that of a regular website search engine, which supports the search for keyword search, search by author, search for more accurate searches through advanced search, etc. Google Scholar also provides a profile page of author's See a lot of information about the author, including the number of citations by year and some statistics, etc. For example, h-index, meaning that the number of citations is more than the number of times the number of articles from these personal pages can also quickly To obtain a general understanding of the results of this person can be said from the side to strengthen the overall functionality of the site and ease of use.

Similar to Google Scholar, Microsoft's Microsoft Academic Search is a free academic search engine developed by Microsoft Research Asia (MSRA). It is based on the use of object-level information retrieval, through Microsoft's own database to find a leading field of academic researchers and top conferences and journals, and even can study the field of prosperity and development of the specific process. Used to find some academic research disciplines within the research hotspots and the rising academic star, etc. Although the search engine is currently included in the computer science and information science related academic data, but this more advanced application function is undoubtedly for the user's experience has greatly improved.

In addition to these foreign companies to develop the academic search engine, there are also colleges and universities to develop their own academic search engines, such as Tsinghua University AMiner and Shanghai Jiaotong University Acemap. These colleges and universities search engine is characterized by the amount of data and Google Scholar can not But the developers pay more attention to the user in the use of academic search engine may need some of the personalized features.For example, Acemap, the user can visualize the way, from large and small very easy to choose their own interest Academic research field, to retrieve the paper, but also through the collaborators map, academic institutions, maps, etc. to fit a variety of personalized needs, to improve the efficiency of the required academic papers.

As in the actual academic research, we tend to pay more attention to the past and the latest research results of a certain field, that is, the academic papers published in this field, as opposed to the research results of a well-known researcher or research institution. Different people are often not concerned about the field to a level of discipline and even two disciplines, but specific to a very detailed direction.For example, the same is concerned about the field of machine learning researchers, some people The focus is on supervising learning while others are more interested in unsupervised learning, and the enhanced learning of the fire now is a very different area. Further, in some similar algorithms, there are different sides This will give us the difficulty of finding a series of interesting papers, relying on a few keywords can not find the required papers, but can not find some of the new ideas and concepts put forward.Through the Authors and collaborators even have a great deal of relevance to the search, because each researcher's research interests and direction are also Changes in the corresponding changes, not just by locking a number of researchers to get interested in the direction and field of the paper.Naturally, we have an idea, how to use existing data to improve our Academic search to use the experience, to better meet us to find a sub-domain of all the quality of the paper's needs?

First of all, taking into account the particularity of academic papers is that its structure is more obvious, most of the published academic papers, basically contains a summary, introduction, text and other parts, which also reflects the academic papers and other text of the difference Because the author is a well-trained scientific workers, the overall structure of the rigor can naturally be guaranteed.Secondly, most of the academic papers through the conference and journal to publish.We naturally think that in the academic papers from writing to In the process of submission, the choice of journals and meetings submitted by the researchers is an artificial label, because the topics and scope of the accepted papers are limited because of the different journals and conferences. Time will change over time, the world's research hotspots change slightly, but still can be used as a basis for judgments, especially academic conferences, as a timeliness of the activities, which published academic papers and The direction is usually very strong time and targeted. Compared with the many journals because it is a long-term publication of the contents of its content by the time And the impact of the times is obvious. Any journal published in the 2016 article and the 2006 article concerned about the hot spot is certainly very different.Obviously, with its direct study of the classification of academic papers, research between the academic conference as a whole Of the relationship, and then through similar meetings to academic papers recommended is a relatively easy and efficient way.

So for a person who understands the data mining, the problem is focused on how to define an academic conference in the area where the machine can know, and simply how to do the feature extraction of the academic conference. It is a natural idea that since academic conferences are an implicit feature of academic papers, if we see academic conferences as a collection of academic papers, then we can clearly define the conference itself by the academic papers it contains. What is the common method of extracting text from a simple word frequency, TF-IDF to N-gram algorithm, simulated annealing algorithm, etc. Here we consider that our ultimate goal is to clarify the academic There is a relative relationship between the meetings, focusing on the relative. So I took Word2vec with very good linear features to achieve the final text vectorization.

The concrete approach is to use the single-layer neural network language model Skip-gram to train the word vector, and then the training of the word vector to cluster.Using clustering to text vectorization.Clustering algorithm also has many choices, including the level Clustering algorithm, hierarchical clustering algorithm and clustering algorithm based on grid and density. Here we choose to use the K-Means algorithm in the partitioned clustering algorithm to cluster.When the clustering vector, Each type represents a class of words that are closer to the academic paper. At this time, we only need to simply compute the word frequency of different types of words, and we can get the vector representing the article.

After we get the text vector, we will further consider the use of text vector to generate the corresponding conference vector. At this time we mainly consider that the conference vector should represent the main trend of academic papers in the academic conference, and the communication between the conference vectors can be To compare the degree of correlation between the previous step, we use different types of words to represent the text vector, then the academic conference of all academic papers in the text vector to take the average, and then through the cosine similarity to compare is A very easy way to think. In fact, this method is indeed able to get very satisfactory results.

\end{bigabstract}
